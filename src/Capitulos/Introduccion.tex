\chapter{Introducción}
\label{cap:introduccion}

% \chapterquote{La revolución industrial y sus consecuencias han sido un desastre para la raza humana}{Theodore Kaczynski}

% En los últimos años se ha visto un gran interés y evolución de las tecnologías de realidad virtual a mano de empresas como Apple con su lanzamiento de las Apple Glasses o Meta con el lanzamiento de las Meta Quest 3 o su interés por el \gls{metaverso} con su aplicación de Meta Horizon Worlds.

% Es por ello que es interesante investigar la comunicación no verbal en entornos virtuales, ya no solo para aplicaciones con varios usuarios si no también para poder mejorar interacciones con \glspl{npc} en este tipo de entornos.

% Nuestra propuesta en este Trabajo de Fin de Grado es una primera aproximación de cómo se puede usar la \gls{ia} y la tecnología de captura de movimiento para lograr esa mejora en las interacciones en los mundos virtuales mediante la comunicación no verbal, siendo este caso la exploración de la capacidad de clasificar distintos gestos.
% Los gestos seleccionados han sido seis gestos que se han útiles a la hora de que un NPC pueda reconocerlo en un videojuego. Estos gestos han sido:
% \begin{enumerate}
% 	%\renewcommand{\theenumi}{\alph{enumi}}
% 	\item Bailar
% 	\item Saludar
% 	\item Señalar
% 	\item Sentarse
% 	\item Pelear
% 	\item Correr
% \end{enumerate}

% Para poder realizar este trabajo se ha requerido usar las gafas de realidad virtual Meta (antes conocidas como Oculus) Quest 2 y 3 y el traje de captura de movimiento Perception Neuron 3, de la empresa Noitom, como hardware y Python C\# y Unity como los requisitos de software.

En los últimos años el avance de tecnologías inmersivas como la \gls{vr} ha proporcionado un gran cambio en la forma en la que los usuarios interactúan en los entornos digitales.
Grandes empresas como Meta o Apple han apostado por el desarrollo de hardware para estas tecnologías con el lanzamiento de Meta Quest 3 y Apple Vision Pro, así como con la creación de plataformas de interacción social en el \gls{metaverso} con el desarrollo de Meta Horizon Worlds.
Esta tecnología ha abierto nuevas oportunidades para explorar modos de comunicación más naturales en espacios virtuales mediante la comunicación no verbal.

La comunicación no verbal es aquella que no se basa en el uso de palabras, sino que utiliza las imágenes y los gestos para transmitir el mensaje.
En nuestro día a día representa una parte esencial de las comunicaciones humanas, sin embargo su representación en entornos virtuales es más limitada y dependiente de acciones predefinidas como animaciones o ''emotes'' ya introducidos en el juego.
Es por esto que el desarrollo de herramientas que permitan capturar e interpretar en tiempo real estos gestos constituye un gran paso hacia entornos virtuales más expresivos y realistas.

Este trabajo se inscribe dentro de la línea de investigación de herramientas que puedan reconocer gestos realizados por un usuario mediante un traje de captura de movimiento.
Para ello partimos de seis gestos que pueden ser de utilidad que un \gls{npc} los sepa identificar a la hora de la comunicación en un videojuego: saludar, señalar, sentarse, pelear, correr y bailar.

Debido a la necesidad de grandes cantidades de datos de las animaciones buscadas, este proyecto también busca la creación de un dataset de los datos mediante bancos de animaciones y captura de movimiento de usuarios.

En resumen, el propósito de este trabajo es la detección de seis gestos en tiempo real mediante un traje de captura de movimiento con el fin de avanzar en la mejora del uso de la comunicación no verbal en espacios virtuales.

\section{Motivación}
Debido al crecimiento de entornos virtuales en los últimos años y a la limitación en estos espacios de representación de una parte tan fundamental de la comunicación en los humanos como es la comunicación no verbal, es interesante investigar formas de ampliar esta representación para que la comunicación entre usuarios y \glspl{npc} sea más natural.

Este estudio propone utilizar un traje de captura de movimiento con el fin de detectar seis gestos en tiempo real: saludar, señalar, sentarse, pelear, correr y bailar.
%Para ello se hará una comparativa entre distintos modelos de \gls{ia} con el fin de encontrar un modelo que pueda llevar a cabo esa predicción de forma adecuada con los datos disponibles, tanto por su precisión como por su rapidez.

Como podemos ver en artículos como \cite{Neverova} o \cite{VRHANDS} la detección de la gestos es un campo de estudio que actualmente se está explorando.
La investigación que nosotros proponemos para aportar a este campo es el uso de un traje de movimiento de cuerpo entero con el fin de detectar seis gestos para su uso en entornos virtuales y videojuegos, siendo esos gestos saludar, señalar, sentarse, pelear, correr y bailar.

\section{Objetivos}
El objetivo principal de este proyecto es investigar la posibilidad de detección de diferentes gestos en tiempo real mediante un traje de captura de movimiento con el fin de mejorar la comunicación no verbal en entornos virtuales.

TO DO: más

Debido a la falta de datasets de animaciones encontrados en el desarrollo del proyecto se estableció como objetivo secundario la publicación del dataset creado con los usuarios.

\section{Plan de trabajo}
Nuestro plan de trabajo consiste en varios pasos:
\begin{enumerate}
	%\renewcommand{\theenumi}{\alph{enumi}}
	\item Búsqueda de un dataset: generar un dataset lo suficientemente grande con varios ejemplos de gestos como para poder entrenar de forma adecuada diferentes modelos.
	\item Implementación de modelos de \gls{ia}: implementación de varios modelos de \gls{ia} para poder hacer una comparativa entre ellos y decidir cuál es el más adecuado teniendo en cuenta su velocidad de predicción y su precisión.
	\item Desarrollo de una aplicación final: desarrollo de una aplicación para las Oculus Quest a forma de demo en la que se conecte al modelo elegido y se pueda ver en tiempo real su uso.
\end{enumerate}