\chapter*{Abstract}

\section*{\tituloPortadaEngVal}
This study focuses on the comparison of different \gls{ai} models for the detection of specific gestures using the Perception Neuron 3 motion capture suit in order to create interactions with \glspl{npc} through non-verbal communication and the creation of tools derived from the models that help non-verbal communication in virtual environments.
To achieve this, artificial data has been obtained through the Mixamo animation bank and real data through user tests (N=65) with the aforementioned suit, in order to generate a dataset of gestures with 3D coordinates.
With the collected and standardized data, a comparison has been made according to their accuracy between four \gls{ai} models from the TensorFlow and YDF libraries: \gls{lstm}, \gls{cnn}, \gls{rnn} and \gls{randomforest}, with the latter being the best model for the case.
With the selected model, a server has been deployed using TensorFlow Serving to use the model in an application developed as a demo with support for \gls{vr} glasses to show the results.

\section*{Keywords}

\noindent Motion capture, Unity, Artificial Intelligence, Non-verbal communication, Perception Neuron, TensorFlow, YDF, Keras, Virtual Reality



